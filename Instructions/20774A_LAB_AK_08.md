# Module 8: Using R and Python with Azure Machine Learning

## Lab: Using R and Python with Machine Learning

### Exercise 1: Preparing the lab

#### Task 1: Create Azure SQL Database

01. On the **20774A-LON-DEV** virtual machine, ensure that you are logged in as **ADATUM\\AdatumAdmin**.
02. On the Start menu, start to type **Internet Explorer**, and then click **Internet Explorer**.
03. In the address bar, type **http://azure.microsoft.com**, click **Portal**, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
04. In the Azure Portal, in the left-hand pane, click **+New**.
05. Select **Databases**, and then select **SQL Database**.
06. Enter the following details, and then click **Server**:
  - Name: **WideWorldImporters-Standard**
  - Resource group (create new): **&lt;*your name*&gt;rg**
  - Select source: **Blank database**
07. On the **Server** pane, click **Create a new server**.
08. On the **New server** pane, enter the following details, and then click **Select**:
  - Server name: **&lt;*your name*&gt;&lt;*date*&gt;**
  - Server admin login: **dbadmin**
  - Password: **Pa55w.rd**
  - Confirm password: **Pa55w.rd**
  - Location: ***Select your region***
09. Click **Pricing tier**, click **Standard**, and then click the left-hand end of the **DTU slider**, so that the **DTU** box shows **10 (S0)**.
10. Click **Apply**.
11. Leave all other details at their defaults, and click **Create**.
12. Make a note of the database and server names that you used.
13. Wait until you see a message that the deployment has been successful.
14. On the **WideWorldImporters-Standard** blade, click the ***Server name***, and then on the **Settings** blade, click **Firewall**.
15. Click **Add client IP**, and then click **Save**, to add your current IP address to the list of allowed IP addresses.
16. In the message box, click **OK**, and then close the Firewall settings, Settings and server blades.

#### Task 2: Import data into Azure SQL Database

1. On the **20774A-LON-DEV** virtual machine, right-click **Start**, and then click **Command Prompt(Admin)**.
2. In the **User Account Control** dialog box, click **Yes**.
3. In the **Command Prompt** window, type the following command, and press Enter:
```
CD C:\\Program Files (x86)\\Microsoft SQL Server\\130\\DAC\\Bin
```
4. In the **Command Prompt** window, type the following command (replacing *&lt;your db servername&gt;* with the name of your database server from the previous task), and press Enter:
```
SqlPackage.exe /a:import /tcs:"Data Source=&lt;*your db servername*&gt;.database.windows.net;Initial Catalog=WideWorldImporters-Standard;User Id=dbadmin;Password=Pa55w.rd" /sf:E:\\Labfiles\\Lab08\\WideWorldImporters-Standard.bacpac /p:DatabaseEdition=Standard /p:DatabaseServiceObjective=S0
```
  The above command can be copied from *E:\\Labfiles\\Lab08\\SqlPackageCmd.txt*.
5. Wait until you get the following message:
```
  Successfully imported database
```
6. Close the command prompt.

>**Results**: At the end of this exercise, you will have created an Azure SQL Database, and imported WideWorldImporters-Standard data into this database.

### Exercise 2: Exploring data using R

#### Task 1: Prepare the product sales data

01.  On the **20774A-LON-DEV** virtual, in Internet Explorer, in the address bar, type **https:// studio.azureml.net**.
02. On the **Microsoft Azure Machine Learning Studio** page, click **Sign In**.
03. If you are prompted for credentials, use the details of the Microsoft account that you created for this course.
04. In Microsoft Azure Machine Learning Studio, in the navigation pane click **EXPERIMENTS**, and then click **+New**.
05. Click **Blank Experiment**.
06. In the experiment items pane, expand **Data Input and Output**, and then drag the **Import Data** module on to the experiment canvas.
07. In the **Properties** pane, click **Launch Import Data Wizard**.
08. In the **Import Data** wizard, on the **Choose data source** page, click **Azure SQL database**, and then click **Next**.
09. On the **Connect to Azure SQL Database** page, in the **Subscription ID** box select **Enter values manually**, provide the following details, and then click **Next**:
   - **Database server name**: &lt;your db servername&gt;.database.windows.net
   - **Database name**: WideWorldImporters-Standard
   - **User name**: dbadmin
   - **Password**: Pa55w.rd
10. On the **Configure Database Query page**, specify the following query and then click the tick button:
```
SELECT StockItemID, Description, Quantity, UnitPrice = CAST(UnitPrice AS INTEGER), PickingCompletedWhen
FROM Sales.OrderLines
```
11. In the experiment items pane, expand **Data Format Conversions**, and drag the **Convert to CSV** module on to the experiment canvas.
12. Connect the **Result Dataset** port on the bottom edge of the **Import Data** module to the port on the upper edge of the **Convert to CSV** module.
13. Click **Run**.
14. When the experiment has completed, right-click the **Convert to CSV** module, click **Results dataset**, and then click **Save as Dataset**.
15. In the **Save output as a new dataset** dialog box, in the **Enter a name for the new dataset** box, type **Wide World Importers**, and then click the tick button.

#### Task 2: Determine the most popular products in the dataset

>**Note:** You can find the comments and code for this lab in the file **Product Sales.txt**, located in the **E:\Labfiles\Lab08** folder.

01. In Microsoft Azure Machine Learning Studio, in the navigation pane, click **DATASETS**, select the **Wide World Importers** dataset, click **OPEN IN NOTEBOOK**, and then click **R**.
02. In the Jupyter notebook, click the first cell.
03. On the **Insert** menu, click **Insert Cell Above**.
04. In the toolbar, change the type of the cell from **Code** to **Markdown**.
05. Add the following text to the cell:
  ```
  # Evaluate Product Sales
  Exploratory exercises over the product orders data for Wide World Importers
  - What are the top 20 most popular products?
  - How do sales of the most popular product vary over time?
  - Is there a pattern to these sales?
  ## What are the most popular products?
  Load the libraries required to perform these tasks.
  ```
06. On the **Insert** menu, click **Insert Cell Below**.
07. Add the following R code to the cell:
  ```
  library(AzureML)
  library(dplyr)
  library(ggplot2)
  library(scales)
  install.packages("xts") # You also need to install the xts package
  library(xts)
  install.packages("broom") # And the broom package
  library(broom)
  ```
08. On the toolbar, click **Run cell**. Verify that the following messages appear:
  ```
  Attaching package: 'dplyr'
  The following object is masked from 'package:stats':
      filter
  The following objects are masked from 'package:base':
      intersect, setdiff, setequal, union
  Installing package into '/home/nbcommon/R'
  (as 'lib' is unspecified)
  The downloaded source packages are in
      '/tmp/Rtmpa6sSUX/downloaded_packages'
  Loading required package: zoo
  Attaching package: 'zoo'
  The following objects are masked from 'package:base':
      as.Date, as.Date.numeric
  Attaching package: 'xts'
  The following objects are masked from 'package:dplyr':
  first, last
  The following object is masked from 'package:AzureML':
      endpoints
  Installing package into '/home/nbcommon/R'
  (as 'lib' is unspecified)
  The downloaded source packages are in
      '/tmp/Rtmpa6sSUX/downloaded_packages'
  ```
09. Locate the cell containing the following code:
  ```
  library("AzureML")
  ws <- workspace()
  dat <- download.datasets(ws, "Wide World Importers")
  ```
10. Change the last line of this code, and add an additional line at the end, as highlighted here:
  ```
  library("AzureML")
  ws <- workspace()
  ordersDataSet <- download.datasets(ws, "Wide World Importers")
  head(ordersDataSet)
  ```
11. On the toolbar, click **Run cell**. Verify that the details for the first six orders appear.
12. Locate the cell containing the following code:
  ```
  head(dat)
  ```
13. In the toolbar, change the type of the cell from **Code** to **Markdown**.
14. Add the following text to the cell:
  ```
  The same product might occur in more than one order. Generate a list of products and their descriptions that have been ordered at least once. Each product should occur only once in the list. Store the result in another dataset called *stockItemsDataSet*.
  ```
15. On the **Insert** menu, click **Insert Cell Below**.
16. Add the following R code to the cell:
  ```
  ordersDataSet %&gt;%
      select(StockItemID, Description) %&gt;%
      distinct() -&gt; stockItemsDataSet
  head(stockItemsDataSet)
  ```
17. On the toolbar, click **Run cell**. Verify that the **StockItemID** and **Description** columns for the first six items appear.
18. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
19. Add the following text to the cell:
  ```
  Find which products are the most popular, using a *dplyr* pipeline as follows:
  - Extract the StockItemID and quantity sold for each order
  - Group the results by StockItemID
  - Sum the quantity sold for each group, and name the column as *numOrdered*
  - Order the results in descending order of *numOrdered* (the most popular items will be at the top of the list)
  - Limit the results to the first 20 rows
  Save the results in another dataset named *numOrderedDataSet*
  ```
20. On the **Insert** menu, click **Insert Cell Below**.
21. Add the following R code to the cell:
  ```
  ordersDataSet %>%
    select(StockItemID, Quantity) %>%
    group_by(StockItemID) %>%
    summarize(numOrdered = sum(Quantity)) %>%
    arrange(desc(numOrdered)) %>%
    filter(row_number() <= 20) -> numOrderedDataSet
  head(numOrderedDataSet)
  ```
22. On the toolbar, click **Run cell**. Verify that the **StockItemID** and **numOrdered** columns for the first six items appear.
23. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
24. Add the following text to the cell:
  ```
  Combine the *numOrderedDataSet* and the *stockItemsDataSet* over the *StockItemID* column so that the list contains the *StockItemID*, *numOrdered*, and *Description* columns
  ```
25. On the **Insert** menu, click **Insert Cell Below**.
26. Add the following R code to the cell:
  ```
  results &lt;- inner\_join(numOrderedDataSet, stockItemsDataSet, by = "StockItemID")
  head(results)
  ```
27. On the toolbar, click **Run cell**. Verify that the **StockItemID**, **numOrdered**, and **Description** columns for the first six items appear.
28. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
29. Add the following text to the cell:
  ```
  Generate a graph showing the product descriptions on the X-axis and the number ordered on the Y-axis
  ```
30. On the **Insert** menu, click **Insert Cell Below**.
31. Add the following R code to the cell:
  ```
  options(repr.plot.width=10, repr.plot.height=8)
  ggplot(results) +
    geom_point(mapping = aes(x = reorder(Description, -numOrdered), y = numOrdered), color = "red", size = 5) +
    labs(x = "Product", y = "Total Ordered") +
    scale_x_discrete(labels = function(x) { lapply(strwrap(x, width = 25, simplify = FALSE), paste, collapse = "\n")}) +
    theme(axis.text.x = element_text(angle = 90, size = 10))
  ```
32. On the toolbar, click **Run cell**. Verify that a graph appears showing the sales for the top 20 most popular products, in order of total sales.

#### Task 3: Investigate how product sales vary over time

01.  Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
02. Add the following text to the cell:
  ```
  ## How do product sales vary over time?
  Product 191 (Black and orange fragile despatch tape 48mmx75m) is the most popular product. How do sales of this product vary over time (if at all)?
  Find all sales of product 191.
  ```
03. On the **Insert** menu, click **Insert Cell Below**.
04. Add the following R code to the cell:
  ```
  ordersDataSet %>%
  filter(StockItemID == 191) -> productSalesDataSet
  head(productSalesDataSet)
  str(productSalesDataSet)
  ```
05. On the toolbar, click **Run cell**. Verify that the list that appears only contains orders for stock item 191. The messages that occur afterwards provide additional information about the structure of the dataset. Note that there should be 1040 rows (observations) in the dataset.
06. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
07. Add the following text to the cell:
  ```
  Reorganize the data as a time series, based on the \*PickingCompletedWhen\* column. Note that this column is actually a string (chr) in month/day/year format, so it needs to be converted to a datetime.
  ```
08. On the **Insert** menu, click **Insert Cell Below**.
09. Add the following R code to the cell:
  ```
  timeSeriesOrders <- xts(productSalesDataSet[c("StockItemID", "Quantity")],
  order.by = as.POSIXct(productSalesDataSet$PickingCompletedWhen, format = "%m%d%Y"))
  head(timeSeriesOrders)
  ```
10. On the toolbar, click **Run cell**. Verify that the following data appears. This is the first six rows from the time series:
  ```
               StockItemID Quantity
  2013-01-02         191      288
  2013-01-02         191      144
  2013-01-02         191      252
  2013-01-02         191      108
  2013-01-03         191      180
  2013-01-04         191      180
  ```
11. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
12. Add the following text to the cell:
  ```
  Work out how many units were ordered each day.
  ```
13. On the **Insert** menu, click **Insert Cell Below**.
14. Add the following R code to the cell:
  ```
  dailyTotals <- apply.daily(timeSeriesOrders, function(x){ apply(x$Quantity, 2, sum)})
  head(dailyTotals)
  ```
15. On the toolbar, click **Run cell**. Verify that the following data appears. This data shows the unit sales for product 191 for each day (the first six rows should be displayed):
  ```
              [,1]
  2013-01-02 792
  2013-01-03 180
  2013-01-04 180
  2013-01-10 324
  2013-01-11 324
  2013-01-14 216
  ```
16. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
17. Add the following text to the cell:
  ```
  Plot a graph showing how the sales vary by day.
  First, the time series must be converted back into a dataframe to work with ggplot.
  ```
18. On the **Insert** menu, click **Insert Cell Below**.
19. Add the following R code to the cell:
  ```
  graphData <- tidy(dailyTotals)
  head(graphData)
  ```
20. On the toolbar, click **Run cell**. Six rows of data should appear, although they will not be particularly meaningful because the first two columns display the data using an internal format.
21. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
22. Add the following text to the cell:
  ```
  Then convert the index column back into a datetime value.
  ```
23. On the **Insert** menu, click **Insert Cell Below**.
24. Add the following R code to the cell:
  ```
  graphData$index <- as.POSIXct(graphData$index, origin="1970-01-01")
  head(graphData)
  ```
25. On the toolbar, click **Run cell**. Six rows of data should appear. The series and value columns should be unchanged from before, but the index should now be recognizable as a date.
26. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
27. Add the following text to the cell:
  ```
  Finally, plot the data.
  ```
28. On the **Insert** menu, click **Insert Cell Below**.
29. Add the following R code to the cell:
  ```
  options(repr.plot.width=15, repr.plot.height=5)
  ggplot(graphData, aes(x = index, y = value)) +
      ggtitle("Product Sales Over Time for Product 191") +
      xlab("Date") +
      ylab("Units Sold") +
      scale_x_datetime(labels = date_format("%Y-%m"), breaks = date_breaks("months")) +
      theme(axis.text.x = element_text(angle = 45)) +
      geom_point(color = "blue")
  ```
30. On the toolbar, click **Run cell**. A graph should appear showing the sales for product 191 over time.

#### Task 4: Examine the data to see whether there is a pattern to product sales

01. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
02. Add the following text to the cell:
```
## Is there a pattern to these sales?
Focus on sales for 2013.
```
03. On the **Insert** menu, click **Insert Cell Below**.
04. Add the following R code to the cell:
  ```
  firstDay <- as.POSIXct("2013-01-01")
  lastDay <- as.POSIXct("2013-12-31")
  day1 <- as.numeric(firstDay)
  dayN <- as.numeric(lastDay)
  productSalesFor2013 <- filter(graphData, (index >= day1) & (index <= dayN))
  options(repr.plot.width=15, repr.plot.height=5)
  ggplot(productSalesFor2013, aes(x = index, y = value)) +
      ggtitle("Product Sales for Product 191 in 2013") +
      xlab("Date") +
      ylab("Units Sold") +
      scale_x_datetime(labels = date_format("%Y-%m"), breaks = date_breaks("months")) +
      theme(axis.text.x = element_text(angle = 45)) +
      geom_point(color = "blue")
  ```
05. On the toolbar, click **Run cell**. A graph should appear showing the sales for product 191 just for 2013.
06. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
07. Add the following text to the cell:
  ```
  Fit a curve to the sales, and then compare to curves for 2014 and 2015 to see if there is a regular pattern.
  ```
08. On the **Insert** menu, click **Insert Cell Below**.
09. Add the following R code to the cell:
  ```
  ggplot(productSalesFor2013, aes(x = index, y = value)) +
  ggtitle("Product Sales for Product 191 in 2013") +
  xlab("Date") +
  ylab("Units Sold") +
  scale_x_datetime(labels = date_format("%Y-%m"), breaks = date_breaks("months")) +
  theme(axis.text.x = element_text(angle = 45)) +
  geom_point(color = "black", alpha = 0.2) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 9))
  ```
10. On the toolbar, click **Run cell**. The same graph as before should appear but with an overlay showing a curve fitted to the sales.
11. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
12. Add the following text to the cell:
  ```
  The graph and curve for 2014.
  ```
13. On the **Insert** menu, click **Insert Cell Below**.
14. Add the following R code to the cell:
  ```
  firstDay <- as.POSIXct("2014-01-01")
  lastDay <- as.POSIXct("2014-12-31")
  day1 <- as.numeric(firstDay)
  dayN <- as.numeric(lastDay)
  productSalesFor2014 <- filter(graphData, (index >= day1) & (index <= dayN))
  ggplot(productSalesFor2014, aes(x = index, y = value)) +
  ggtitle("Product Sales for Product 191 in 2014") +
  xlab("Date") +
  ylab("Units Sold") +
  scale_x_datetime(labels = date_format("%Y-%m"), breaks = date_breaks("months")) +
  theme(axis.text.x = element_text(angle = 45)) +
  geom_point(color = "black", alpha = 0.2) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 9))
  ```
15. On the toolbar, click **Run cell**. A graph with a curve showing the sales for 2014 should appear.
16. Click the new cell created at the end of the notebook. Change the type of the cell from **Code** to **Markdown**.
17. Add the following text to the cell:
  ```
  The graph and curve for 2015.
  ```
18. On the **Insert** menu, click **Insert Cell Below**.
19. Add the following R code to the cell:
  ```
  firstDay <- as.POSIXct("2015-01-01")
  lastDay <- as.POSIXct("2015-12-31")
  day1 <- as.numeric(firstDay)
  dayN <- as.numeric(lastDay)
  productSalesFor2015 <- filter(graphData, (index >= day1) & (index <= dayN))
  ggplot(productSalesFor2015, aes(x = index, y = value)) +
      ggtitle("Product Sales for Product 191 in 2015") +
      xlab("Date") +
      ylab("Units Sold") +
      scale_x_datetime(labels = date_format("%Y-%m"), breaks = date_breaks("months")) +
      theme(axis.text.x = element_text(angle = 45)) +
      geom_point(color = "black", alpha = 0.2) +
      geom_smooth(method = "lm", formula = y ~ poly(x, 9)
  ```
20. On the toolbar, click **Run cell**. A graph with a curve showing the sales for 2015 should appear.

#### Task 5: Run the Jupyter notebook

01.  On the **Kernel** menu, click **Restart & Run All**.
02. In the **Restart kernel and re-run the whole notebook?** message box, click **Restart & run all cells**.
03. Wait while each step runs. Notice that the markdown cells are formatted. The result should be fully documented code explaining the process that you followed.
04. In the toolbar, click **Save and Checkpoint**.
05. On the **File** menu, click **Close and Halt**.

>**Results**: At the end of this exercise, you will have created datasets containing the top 20 products that comprise the most units sold and the top 20 products that constitute the most sales value. You will also have created graphs that illustrate how the sales of these products vary across the year, and you will have documented the entire process in a Jupyter notebook

### Exercise 3: Analyzing data using Python

#### Task 1: Create the experiment and prepare the data

>**Note:** You can find the comments and code for this exercise in the file **Python Data.txt**, located in the **E:\\Labfiles\\Lab08** folder.

01.  In Microsoft Azure Machine Learning Studio, ensure that **EXPERIMENTS** is selected in the navigation pane, and then click **+ NEW**.
02. Click **Blank Experiment**.
03. In the **Search experiment** **items** box, start to type **Adult**, and then from the module list, drag the **Adult Census Income Binary Classification** dataset module onto the experiment canvas.
04. In the **Search experiment** **items** box, start to type **Select**, and then from the module list, drag the **Select Columns in Dataset** module onto the experiment canvas.
05. Connect the output port of the **Adult Census Income Binary Classification** dataset module to the input port of the **Select Columns in Dataset** module.
06. In the **Properties** pane for the **Select Columns in Dataset** module, click **Launch column selector**.
07. In the **Select columns** dialog box, in the **Available Columns** list, select the **age**, **education-num**, **sex**, **native-country**, **income**, and **fnlwgt** columns, click the **>** button to transfer them to the **Selected Columns** list, and then click the tick button.
08. In the **Search experiment** **items** box, start to type **Python**, and then from the module list, drag the **Execute Python Script** module onto the experiment canvas.
09. In the **Properties** window, in the **Python Version** drop-down list box, click **Anaconda 4.0/Python 3.5**.
10. Connect the output port of the **Select Columns in Dataset** module to the leftmost input port of the **Execute Python Script** module.
11. In the **Properties** pane for the **Execute Python Script** module, click the **Popout the script editor** button.
12. Replace the the **azureml\_main** function with the following Python code, and then click the tick button:
  ```
  def azureml_main(dataframe1 = None):
  import pandas as pd
  # Only use the columns of interest and restrict the rows to those in the US
  censusData = dataframe1[['age', 'fnlwgt', 'education-num', 'sex', 'native-country', 'income']]
  censusData = censusData.loc[censusData['native-country'] == "United-States"]
  del censusData['native-country']
  # factorize the sex column
  censusData['sex'], sex_index = pd.factorize(censusData['sex'])
  return censusData
```
13. Click **Run** to test the experiment. Verify that it executes without any errors.
14. When the experiment has completed, right-click the **Execute Python Script** module, click **Result Dataset**, and then click **Visualize**. Verify that the result dataset only contains the **age**, **fnlwgt**, **education-num**, **sex**, and **income** variables. Note that the sex column is now numeric (0, and 1) where previously it was text (Male, Female).
15. Close the **Visualize** window.

#### Task 2: Split the data and perform Ada Boosted Regression

>**Note:** You can find the comments and code for this exercise in the file **Python Model.txt**, located in the **E:\Labfiles\Lab08** folder.

01. In the **Search experiment items** box, start to type **Split**, and then from the module list, drag the **Split Data** module onto the experiment canvas.
02. In the **Properties** window, set **Fraction of rows in first output dataset** to **0.9**.
03. Connect the leftmost output port of the **Execute Python Script** module to the input port of the **Split Data** module.
04. In the **Search experiment** **items** box, start to type **Python**, and then from the module list, drag the **Execute Python Script** module onto the experiment canvas.
05. Connect the left output port of the **Split Data** module to the leftmost input port of the new **Execute Python Script** module.
06. Connect the right output port of the **Split Data** module to the middle input port of the **Execute Python Script** module.
07. In the **Properties** pane for the new **Execute Python Script** module, click the **Popout the script editor** button.
08. Delete all the code in the editor.
09. Add the following statements to the top of the blank script in the editor:
  ```
  # Create and test a model to predict income based on age, working class, education, and gender
  import pandas as pd
  import sklearn.ensemble as ensemble
  import sklearn.metrics as metrics
  import matplotlib
  matplotlib.use("agg")
  import matplotlib.pyplot as plt
  ```
10. Add the following code to the script:
  ```
  def azureml_main(censusTraining = None, censusTest = None):
    # Train the model
    classifier = ensemble.AdaBoostClassifier()
    classifier.fit(censusTraining[["age", "fnlwgt", "education-num", "sex"]], censusTraining["income"])
  ```
>**Note:** It is important to retain the same indentation as shown in this code. Python uses indentation to determine when the code for a function is complete. If you indent the code differently, the code might not run correctly.

11. Add the following code to the script:
  ```
  # Make predictions using the model and test data
  predictions = classifier.predict(censusTest[["age", "fnlwgt", "education-num", "sex"]])
  ```
12. Add the following code to the script:
  ```
  # Examine the confusion matrix to assess the accuracy of the model
  conf = metrics.confusion_matrix(censusTest["income"], predictions)
  print(pd.crosstab(censusTest["income"], predictions, rownames=['True'], colnames=['Predicted'], margins=True))
  ```
13. Add the following code to the script:
  ```
  # Visualize the confusion matrix
  plt.title('Confusion Matrix')
  plt.imshow(conf, cmap='binary', interpolation='None')
  plt.savefig("confusion.png")
  plt.clf()
  ```
14. Add the following code to the script:
  ```
  # Calculate the ROC AUC score
  censusTest['income'], income\_index = pd.factorize(censusTest['income'])
  predictedIncomes = pd.factorize(predictions)
  rocData = metrics.roc\_curve(censusTest["income"], predictedIncomes[0])
  rocAuc = metrics.roc\_auc\_score(censusTest["income"], predictedIncomes[0])
  ```
15. Add the following code to the script:
  ```
  # Plot the ROC curve
  plt.plot(rocData[0], rocData[1], label='ROC curve (area = %0.3f)' % rocAuc)
  plt.plot([0, 1], [0, 1], 'k--') \# random predictions curve
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.0])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('Receiver Operating Characteristic')
  plt.legend(loc="lower right")
  plt.show()
  plt.savefig("roc.png")
  return censusTraining
  ```
16. Click the tick button to return to the experiment canvas.

#### Task 3: Run the experiment and examine the results

1.  Click **Run** to test the experiment. Verify that it executes without any errors.
2. When the experiment has completed, right-click the **Execute Python Script** module, click **Python Device**, and then click **Visualize**.
3. Scroll through the standard output until you get to the confusion matrix, which should look like this:
  ```
  Predicted   <=50K   >50K    All
  True
  <=50K       2105    139   2244
  >50K        440     233   673
  All         2545    372   2917
  ```
4. Scroll down to the graphics section in the output. You should see a graphical representation of the confusion matrix, followed by the ROC curve for the model.
5. Close the **Visualization** window.
6. Click **Save**.

>**Results**: At the end of this exercise, you will have used Execute Python Script modules in a Machine Learning experiment.

©2017 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
