# Module 4: Preparing Data for use with Azure Machine Learning

## Lab: Preparing data for use with Machine Learning

### Exercise 1: Explore data using Power BI

#### Task 1: Use Power BI to connect to Azure SQL Database

1. On the desktop, double-click **Power BI Desktop**.
2. On the Welcome page, click **Get Data**.
3. In the **Get Data** dialog box, click **Azure**, click **Microsoft Azure** **SQL Database**, and then click **Connect**.
4. In the **SQL Server database** dialog box, in the **Server** box, type **&lt;*your db servername*&gt;.database.windows.net** (replacing &lt;your *db servername*&gt; with the name of your database server from Lab 3).
5. In the Database box, type WideWorldImporters-Standard, and then click OK.
6. In the next **SQL Server database** dialog box, click **Database**, enter the following credentials, and then click **Connect**:
 - Username: **dbadmin**
 - Password: **Pa55w.rd**
7. If your connection is successful, the **Navigator** dialog box will display.

#### Task 2: Use Power BI to explore and chart data stored in Azure SQL Database

01. In the **Navigator** dialog box, select the following tables, and click **Load**:
 - Application Cities
 - Application.Countries
 - Sales.Customers
 - Sales.InvoiceLines
 - Sales.Invoices
02. Wait for the load process to complete; this might take several minutes.
03. On the **Fields** tab, verify that you see the following listed:
 - Application Cities
 - Application Countries
 - Sales Customers
 - Sales InvoiceLines
 - Sales Invoices
04. To create a bar chart, expand **Sales InvoiceLines**, and select **LineProfit**, expand **Sales Invoices**, and then select **InvoiceDate**.
05. Click the chart, then on the **Home** tab, click **Copy**.
06. Click in an empty area of the Power BI canvas, and then on the **Home** tab, click **Paste**.
07. Confirm that you now have two identical charts.
08. Click the second chart, then on the **Visualizations** pane, under **Value**, select **Minimum**. This will show you the largest amount of any loss on the line profit.
09. Click the second chart, and then click the **Format** (paint roller) icon.
10. Expand **Background**, and set the color to something other than white.
11. Confirm that the chart shows that the largest loss of line profit took place in 2016.

>**Results**: At the end of this exercise, you will have used Power BI to connect to Azure SQL Database, and then used Power BI to explore the data.

### Exercise 2: Preprocess data using Machine Learning Studio

#### Task 1: Clean a Machine Learning dataset

01. On the **20774A-LON-DEV** virtual machine, ensure that you are logged in as **ADATUM\AdatumAdmin**.
02. On the Start menu, start to type **Internet Explorer**, and then click **Internet Explorer**.
03. Go to Machine Learning Studio at **https://studio.azureml.net/**.
04. On the Microsoft Azure Machine Learning Studio page, click Sign In.
05. If you are prompted for credentials, use the details of the Microsoft account that you created previously.
06. In Machine Learning Studio, ensure that **EXPERIMENTS** is selected in the navigation pane, click **MY EXPERIMENTS**, and then click **Import Data into Azure ML**.
07. Click **SAVE AS** at the bottom of the page.
08. In the **EXPERIMENT NAME** box, type **Process Data in Azure ML**, and click the tick.
09. Right-click the left-hand **Import Data** module (the one used to import data from Azure Blob storage), and click **Delete**.
10. Repeat the previous step for the **Convert to Dataset** **module**, and for the **Split Data** module.
11. In the **Search experiment items** box, start to type **Remove**, and then, from the module list, drag **Remove Duplicate Rows** on to the experiment canvas.
12. Connect the input port of the **Remove Duplicate Rows** module to the output port of the **Import Data** module.
13. In the Properties pane, click Launch column selector.
14. In the **Select columns** dialog box, under **AVAILABLE COLUMNS**, click each column in turn, click the right arrow, and then click the tick.
15. In the **Search experiment items** box, start to type **Clean**, and then, from the module list, drag **Clean Missing Data** on to the experiment canvas.
16. Connect the input port of the **Clean Missing Data** module to the output port of the **Remove Duplicate Rows** module.
17. Run the experiment, by clicking **RUN** at the bottom of the page.
18. Note that, when the experiment has finished running, you will get a failure from the **Clean Missing Data** module, because you did not specify what to do with missing data.
19. Right-click the output (lower) port of the **Summarize Data** module, and then click **Visualize**.
20. Note that there are 97,547 **Customer Names** in total, but only 97,147 **Transaction Amounts**, so there are 400 rows with missing values. This is confirmed in the **Missing Values** **Count** column. Four columns are missing data:
 - TransactionAmount
 - OutstandingBalance
 - TaskAmount
 - TransactionDate
21. Close the visualization by clicking the **x** at the top-right of the window.
22. Copy and paste the **Clean Missing Data** module twice, so that there are three instances of this module on the experiment canvas.
23. Drag the **Clean Missing Data** modules, so that theyâ€™re on the same horizontal plane, and set equally apart.
24. Connect the output port of the **Remove Duplicate Rows** task to each of the input ports of each **Clean Missing Data** module.
25. Click the left-hand **Clean Missing Data** module, and in the **Properties** pane, click **Launch Column Selector**.
26. In the **Select columns** dialog box, ensure that **WITH RULES** is selected, then under **Begin With**, click **No Columns**.
27. Click the list next to **Include**, and select **column type**, and in the right-hand list, select **Numeric**, and then click the tick.
28. Click the central **Clean Missing Data** module, and in the **Properties** pane, under **Cleaning Mode**, click **Remove entire row**.
29. Click the right-hand **Clean Missing Data** module, and in the **Properties** pane, click **Launch Column Selector**.
30. In the **Select columns** dialog box, ensure that **WITH RULES** is selected, then under **Begin With**, click **No Columns**.
31. Click the list next to **Include**, and select **column type**, and in the right-hand list, select **Numeric**, and then click the tick.
32. In the Properties pane, under Cleaning Mode, click Replace using Probabilistic PCA.
33. In the Properties pane, select Generate missing value indicator.
34. Run the experiment, by clicking **RUN** at the bottom of the page.
35. When the experiment has finished running, click the output port of the **Import Data** module, and then click **Visualize**.
36. Note that the original data comprises 97,547 rows and five columns.
37. Close the visualization by clicking the **x** at the top-right of the window.
38. Click the output port of the **Remove Duplicate Rows** module, and then click **Visualize**.
39. Note that there are now **97,321** rows so Machine Learning has found, and removed, 226 duplicate rows from the original dataset.
40. Close the visualization by clicking the **x** at the top-right of the window.
41. Click the left-hand output port of the left-hand **Clean Missing Data** module, and then click **Visualize**.
42. Note that the dataset contains five columns and **97,321** rows; no rows have been removed, and any missing data will be replaced by the median of that column.
43. Close the visualization by clicking the **x** at the top-right of the window.
44. Click the left-hand output port of the central **Clean Missing Data** module, and then click **Visualize**.
45. Note that the dataset contains five columns and **96,921** rows; in this case, all the rows that had missing data (400 rows) have been removed.
46. Click the left-hand output port of the right-hand **Clean Missing Data** module, and then click **Visualize**.
47. Note that the dataset contains **97,321** rows; no rows have been removed, and any missing data will be replaced by the PCA operation.
48. Close the visualization by clicking the **x** at the top-right of the window.
49. Click **SAVE** at the bottom of the page.

#### Task 2: Normalize a Machine Learning dataset

01. In Machine Learning Studio, ensure that **EXPERIMENTS** is selected in the navigation pane, then click **MY EXPERIMENTS**, and then click **Import Data into Azure ML**.
02. Click **SAVE AS** at the bottom of the page.
03. In the EXPERIMENT NAME box, type Normalize Data in Azure ML, and click the tick.
04. Run the experiment, by clicking **RUN** at the bottom of the page.
05. Right-click the output (lower) port of the **Summarize Data** module, and then click **Visualize**.
06. Note that **TransactionAmount** ranges from -169387 to 36829.
07. Close the visualization by clicking the **x** at the top-right of the window.
08. In the **Search experiment items** box, start to type **Normalize**, and then from the module list, drag **Normalize Data** on to the experiment canvas.
09. Connect the input port of the **Normalize Data** module to the output port of the left-hand **Convert to Dataset** module.
10. Click the **Normalize Data** module, and then in the **Properties** pane, click **Launch column selector**.
11. In the **Select Columns** dialog box, change the **Include** option from column type to **column names**, and in the text box, type **TransactionAmount**, then click the tick.
12. In the **Properties** pane, in the **Transformation method** list, select the **MinMax** option, to rescale **TransactionAmount** so that the values are between 0 and 1.
13. Right-click the **Normalize Data** module, and click **Copy**.
14. Right-click the experiment canvas, and click **Paste**.
15. Connect the input (top) port of the pasted **Normalize Data** module to the output node of the right-hand **Convert to Dataset** module.
16. You should now have two **Normalize Data** tasks.
17. In the **Search experiment items** box, start to type **Summarize**, and then from the module list, drag **Summarize Data** on to the left side of the experiment canvas.
18. Click the left-hand **Normalize Data** module, and the left-hand output node will show the number 1. Click this output node, and connect it to the input (top) port of the **Summarize Data** module.
19. Right-click the **Summarize Data** module, and click **Copy**.
20. Right-click the experiment canvas, and click **Paste**.
21. Drag the pasted **Summarize Data** module to the right side of the canvas.
22. Click the right-hand **Normalize Data** module, and the left-hand output node will show the number 1. Click this output node, and connect it to the input (top) port of the pasted **Summarize Data** module.
23. Run the experiment, by clicking **RUN** at the bottom of the page.
24. When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished.
25. When the experiment has run successfully, right-click the output (lower) port of the left-hand **Summarize Data** module, and then click **Visualize**.
26. Note that **TransactionAmount** now ranges from 0 to 1, with a mean of 0.799168.
27. Close the visualization by clicking the **x** at the top-right of the window.
28. Right-click the output (lower) port of the right-hand **Summarize Data** module, and then click **Visualize**.
29. Note that **TransactionAmount** now ranges from 0 to 1, with a mean of 0.837266.
30. Close the visualization by clicking the **x** at the top-right of the window.
31. Click **SAVE** at the bottom of the page.

#### Task 3: Remove outliers from a Machine Learning dataset

01. In Machine Learning Studio, ensure that **EXPERIMENTS** is selected in the navigation pane, click **MY EXPERIMENTS**, and then click **Process Data in Azure ML**.
02. Click **SAVE AS** at the bottom of the page.
03. In the EXPERIMENT NAME box, type Process Outliers in Azure ML, and click the tick.
04. Click the link between **Import Data** and **Remove Duplicate Rows**, and press Delete.
05. In the **Search experiment items** box, start to type **Clip**, and then from the module list, drag **Clip Values** on to the experiment canvas.
06. Connect the input (top) port of the **Clip Values** module to the output port of the **Import Data** module.
07. Connect the output (lower) port of the **Clip Values** module to the input (top) port of the **Remove Duplicate Rows** module.
08. Click Clip Values, and in the Properties pane, click Launch column selector.
09. In the **Select Columns** dialog box, change the **Include** option from column type to **column names**, and in the box, select **TransactionAmount**, then click the tick.
10. In the **Properties** pane, set the following values:
 - Set of thresholds: **ClipSubpeaks**
 - Lower threshold: **Constant**
 - Constant value for lower threshold: **75**
 - Lower substitute value: **Median**
11. Run the experiment, by clicking **RUN** at the bottom of the page.
12. When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished.
13. When the experiment has run successfully, right-click the output (lower) port of the left-hand **Clip Values** module, and then click **Visualize**.
14. Click the **TransactionAmount** column.
15. Note that, in the **Statistics** pane, **TransactionAmount** now ranges from 75.21 to 36829, so all values below 75 have now been replaced based on the median of the dataset.
16. Close the visualization by clicking the **x** at the top-right of the window.
17. Click **SAVE** at the bottom of the page.

>**Results**: At the end of this exercise, you will have cleaned a dataset, normalized a set of values, and used clipping to remove outliers from data.

Â©2017 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
